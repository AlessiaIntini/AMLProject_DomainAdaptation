{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/peppe-sc/AML_project_poliTO/blob/test_GS/AML_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "46Fyb3T0L984",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4d3c41f5-912c-4f93-8ef9-5988eb9c8bef"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#!jar xvf  \"/content/drive/MyDrive/AML/Cityscapes.zip\""
      ],
      "metadata": {
        "id": "uA1jURCaWA2t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!jar xvf  \"/content/drive/MyDrive/AML/GTA5.zip\"\n",
        "!pip install tensorboardX"
      ],
      "metadata": {
        "id": "ZP9XrMiFafRD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c3b1295f-2180-45b5-9723-2b4e4c7bb6d2"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.10/dist-packages (2.6.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.23.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (23.2)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (3.20.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import os.path\n",
        "\n",
        "if not os.path.isdir('/content/AML_project_poliTO'):\n",
        "  !git clone -b test_GS https://github.com/peppe-sc/AML_project_poliTO.git\n",
        "  %cd AML_project_poliTO\n",
        "\n",
        "if os.path.isdir('./AML_project_poliTO'):\n",
        "  %cd AML_project_poliTO\n",
        "\n",
        "\n",
        "!git pull origin test_GS\n",
        "\n"
      ],
      "metadata": {
        "id": "1AvkVqojIyOq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3834b2c9-83cd-430b-c9ed-956eed5a88f8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/AML_project_poliTO\n",
            "From https://github.com/peppe-sc/AML_project_poliTO\n",
            " * branch            test_GS    -> FETCH_HEAD\n",
            "Already up to date.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = \"adam\"\n",
        "num_epochs = 50\n",
        "learning_rate = 0.01\n",
        "batch_size = 5\n",
        "num_classes = 19\n",
        "checkpoint_step = 1\n",
        "save_model_path = \"/content/my_checkpoint\"\n",
        "validation_step = 10\n",
        "mode = \"train\"\n",
        "num_workers = 2\n",
        "backbone = \"STDCNet813\"\n",
        "pretrain_path =\"checkpoints/STDCNet813M_73.91.tar\" #\"checkpoints/latest.pth\" #\"checkpoints/STDCNet813M_73.91.tar\"\n",
        "use_conv_last = False\n",
        "use_gpu = True\n",
        "n_classes = num_classes\n",
        "\n",
        "\n",
        "start_epoch = 0\n",
        "for check in os.listdir('/content/AML_project_poliTO/checkpoints'):\n",
        "  if 'latest_' in check:\n",
        "\n",
        "    start_epoch_tmp = int(check.split('_')[1].replace('.pth',''))\n",
        "\n",
        "    if start_epoch_tmp >= start_epoch:\n",
        "      start_epoch = start_epoch_tmp+1\n",
        "      pretrain_path = \"checkpoints/\"+check\n",
        "\n",
        "\n",
        "print(\"Starting at Epoch: \" + str(start_epoch))"
      ],
      "metadata": {
        "id": "8cu2OZFK_UvK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24bc5a5e-3f1f-4b5f-ee38-5c3374f30dfc"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting at Epoch: 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import logging\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Subset, DataLoader\n",
        "from torch.backends import cudnn\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import v2\n",
        "from torchvision.models import alexnet\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "zh2kEiYAOaSp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from model.model_stages import BiSeNet\n",
        "from cityscapes import CityScapes\n",
        "from gta5 import GTA5\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import logging\n",
        "import argparse\n",
        "import numpy as np\n",
        "\n",
        "from tensorboardX import SummaryWriter\n",
        "import torch.cuda.amp as amp\n",
        "from utils import poly_lr_scheduler\n",
        "from utils import reverse_one_hot, compute_global_accuracy, fast_hist, per_class_iu\n",
        "from tqdm import tqdm\n",
        "\n",
        "logger = logging.getLogger()\n",
        "\n",
        "\n",
        "def val(model, dataloader):\n",
        "    print('start val!')\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        precision_record = []\n",
        "        hist = np.zeros((num_classes, num_classes))\n",
        "        for i, (data, label) in enumerate(dataloader):\n",
        "            label = label.type(torch.LongTensor)\n",
        "            data = data.cuda()\n",
        "            label = label.long().cuda()\n",
        "\n",
        "            # get RGB predict image\n",
        "            predict, _, _ = model(data)\n",
        "            predict = predict.squeeze(0)\n",
        "            predict = reverse_one_hot(predict)\n",
        "            predict = np.array(predict.cpu())\n",
        "\n",
        "            # get RGB label image\n",
        "            label = label.squeeze()\n",
        "            label = np.array(label.cpu())\n",
        "\n",
        "            # compute per pixel accuracy\n",
        "            precision = compute_global_accuracy(predict, label)\n",
        "            hist += fast_hist(label.flatten(), predict.flatten(), num_classes)\n",
        "\n",
        "            # there is no need to transform the one-hot array to visual RGB array\n",
        "            # predict = colour_code_segmentation(np.array(predict), label_info)\n",
        "            # label = colour_code_segmentation(np.array(label), label_info)\n",
        "            precision_record.append(precision)\n",
        "\n",
        "        precision = np.mean(precision_record)\n",
        "        miou_list = per_class_iu(hist)\n",
        "        miou = np.mean(miou_list)\n",
        "        print('precision per pixel for test: %.3f' % precision)\n",
        "        print('mIoU for validation: %.3f' % miou)\n",
        "        print(f'mIoU per class: {miou_list}')\n",
        "\n",
        "        return precision, miou\n",
        "\n",
        "def str2bool(v):\n",
        "    if v.lower() in ('yes', 'true', 't', 'y', '1'):\n",
        "        return True\n",
        "    elif v.lower() in ('no', 'false', 'f', 'n', '0'):\n",
        "        return False\n",
        "    else:\n",
        "        raise argparse.ArgumentTypeError('Unsupported value encountered.')"
      ],
      "metadata": {
        "id": "Ou_pPybq-Zv7"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import math\n",
        "def train( model, optimizer, dataloader_train, dataloader_val):\n",
        "    writer = SummaryWriter(comment=''.format(optimizer))\n",
        "    nans = []\n",
        "    scaler = amp.GradScaler()\n",
        "\n",
        "    loss_func = torch.nn.CrossEntropyLoss(ignore_index=255)\n",
        "    max_miou = 0\n",
        "    step = start_epoch #0\n",
        "    for epoch in range(start_epoch,num_epochs):\n",
        "        lr = poly_lr_scheduler(optimizer, learning_rate, iter=epoch, max_iter=num_epochs)\n",
        "        model.train()\n",
        "        tq = tqdm(total=len(dataloader_train) * batch_size)\n",
        "        tq.set_description('epoch %d, lr %f' % (epoch, lr))\n",
        "        loss_record = []\n",
        "        for i, (data, label) in enumerate(dataloader_train):\n",
        "            data = data.cuda()\n",
        "            label = label.long().cuda()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "           #print(\"\\n\")\n",
        "           #print(data.size())\n",
        "           #print(\"\\n\")\n",
        "           #print(label.size())\n",
        "           #print(torch.squeeze(label,1).size())\n",
        "           #print(\"\\n\")\n",
        "\n",
        "            with amp.autocast():\n",
        "                output, out16, out32 = model(data)\n",
        "                #print(\"###\")\n",
        "                #print(label.squeeze(1).size())\n",
        "                #print(\"###\")\n",
        "                #print(out16.size())\n",
        "                #print(\"###\")\n",
        "                #print(out32.size())\n",
        "                loss1 = loss_func(output, label.squeeze(1))\n",
        "                loss2 = loss_func(out16, label.squeeze(1))\n",
        "                loss3 = loss_func(out32, label.squeeze(1))\n",
        "                loss = loss1 + loss2 + loss3\n",
        "                #print(loss)\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            tq.update(batch_size)\n",
        "            tq.set_postfix(loss='%.6f' % loss)\n",
        "            step += 1\n",
        "            writer.add_scalar('loss_step', loss, step)\n",
        "            loss_record.append(loss.item())\n",
        "            if math.isnan(loss.item()):\n",
        "              nans.append(loss.item())\n",
        "        tq.close()\n",
        "        loss_train_mean = np.mean(loss_record)\n",
        "        writer.add_scalar('epoch/loss_epoch_train', float(loss_train_mean), epoch)\n",
        "        print('loss for train : %f' % (loss_train_mean))\n",
        "        if epoch % checkpoint_step == 0 and epoch != 0:\n",
        "            #print(\"\\n\")\n",
        "            #print(nans)\n",
        "            #print(\"\\n\")\n",
        "            import os\n",
        "            if not os.path.isdir(save_model_path):\n",
        "                os.mkdir(save_model_path)\n",
        "            torch.save({'state_dict':model.module.state_dict(),'optimizer_state_dict': optimizer.state_dict()}, os.path.join(save_model_path, 'latest_'+str(epoch)+'.pth'))\n",
        "\n",
        "        if epoch % validation_step == 0 and epoch != 0:\n",
        "            precision, miou = val( model, dataloader_val)\n",
        "            if miou > max_miou:\n",
        "                max_miou = miou\n",
        "                import os\n",
        "                os.makedirs(save_model_path, exist_ok=True)\n",
        "                torch.save(model.module.state_dict(), os.path.join(save_model_path, 'best.pth'))\n",
        "            writer.add_scalar('epoch/precision_val', precision, epoch)\n",
        "            writer.add_scalar('epoch/miou val', miou, epoch)\n"
      ],
      "metadata": {
        "id": "x3axJUL7-5HA"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = CityScapes(mode='train',rootpth='/content/Cityscapes/Cityspaces')\n",
        "dataloader_train = DataLoader(train_dataset,\n",
        "                batch_size=batch_size,\n",
        "                shuffle=False,\n",
        "                num_workers=num_workers,\n",
        "                pin_memory=False,\n",
        "                drop_last=True)\n",
        "\n",
        "val_dataset = CityScapes(mode='val',rootpth='/content/Cityscapes/Cityspaces')\n",
        "dataloader_val = DataLoader(val_dataset,\n",
        "                   batch_size=1,\n",
        "                   shuffle=False,\n",
        "                   num_workers=num_workers,\n",
        "                   drop_last=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "39jxZvuHmWrA",
        "outputId": "c8c3ef70-6663-40cf-88ce-550a46757585"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "self.mode train\n",
            "self.len train 1572\n",
            "self.mode val\n",
            "self.len val 500\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = GTA5(mode='train',rootpth='/content/Cityscapes/GTA5')\n",
        "dataloader_train = DataLoader(train_dataset,\n",
        "                batch_size=batch_size,\n",
        "                shuffle=False,\n",
        "                num_workers=num_workers,\n",
        "                pin_memory=False,\n",
        "                drop_last=True)\n",
        "\n",
        "val_dataset = GTA5(mode='val',rootpth='/content/Cityscapes/GTA5')\n",
        "dataloader_val = DataLoader(val_dataset,\n",
        "                   batch_size=1,\n",
        "                   shuffle=False,\n",
        "                   num_workers=num_workers,\n",
        "                   drop_last=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 383
        },
        "id": "IjeNYKGAmZdn",
        "outputId": "d2d20c7b-3b5b-48dc-ca4d-8802e83a3bfd"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "self.mode train\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-b31f004c8a50>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGTA5\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mrootpth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'/content/Cityscapes/GTA5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m dataloader_train = DataLoader(train_dataset,\n\u001b[1;32m      3\u001b[0m                 \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m                 \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                 \u001b[0mnum_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_workers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/AML_project_poliTO/gta5.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, rootpth, cropsize, mode, randomscale, *args, **kwargs)\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0mimgnames\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m         \u001b[0mimpth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mosp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrootpth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'images'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimpth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mim_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mimages\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mim_name\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.png'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/Cityscapes/GTA5/images'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## model\n",
        "#print(torch.load(pretrain_path))\n",
        "model = BiSeNet(backbone=backbone, n_classes=n_classes, pretrain_model=\"checkpoints/STDCNet813M_73.91.tar\", use_conv_last=use_conv_last)\n",
        "\n",
        "#if pretrain_path != \"checkpoints/STDCNet813M_73.91.tar\":\n",
        "#  checkpoint = torch.load(pretrain_path)\n",
        "#  model.load_state_dict(checkpoint['state_dict'])\n",
        "\n",
        "if torch.cuda.is_available() and use_gpu:\n",
        "    model = torch.nn.DataParallel(model).cuda()\n",
        "\n",
        "## optimizer\n",
        "# build optimizer\n",
        "print(optimizer)\n",
        "if optimizer == 'rmsprop':\n",
        "    optimizer = torch.optim.RMSprop(model.parameters(), learning_rate)\n",
        "elif optimizer == 'sgd':\n",
        "    optimizer = torch.optim.SGD(model.parameters(), learning_rate, momentum=0.9, weight_decay=1e-4)\n",
        "elif optimizer == 'adam':\n",
        "    optimizer = torch.optim.Adam(model.parameters(), learning_rate)\n",
        "else:  # rmsprop\n",
        "    print('not supported optimizer, using adam\\n')\n",
        "    optimizer = torch.optim.Adam(model.parameters(), learning_rate)\n",
        "\n",
        "if pretrain_path != \"checkpoints/STDCNet813M_73.91.tar\":\n",
        "\n",
        "  checkpoint = torch.load(pretrain_path)\n",
        "  model.module.load_state_dict(checkpoint['state_dict'])\n",
        "  optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "## train loop\n",
        "\n",
        "train(model, optimizer, dataloader_train, dataloader_val)\n",
        "# final test\n",
        "val(model, dataloader_val)"
      ],
      "metadata": {
        "id": "XdrrqByPB1gC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 685
        },
        "outputId": "f9c8bbfe-110e-491f-e126-2d251bfabf66"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "use pretrain model checkpoints/STDCNet813M_73.91.tar\n",
            "Adam (\n",
            "Parameter Group 0\n",
            "    amsgrad: False\n",
            "    betas: (0.9, 0.999)\n",
            "    capturable: False\n",
            "    differentiable: False\n",
            "    eps: 1e-08\n",
            "    foreach: None\n",
            "    fused: None\n",
            "    lr: 0.01\n",
            "    maximize: False\n",
            "    weight_decay: 0\n",
            ")\n",
            "not supported optimizer, using adam\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "epoch 2, lr 0.009639:   4%|▍         | 60/1570 [00:31<11:43,  2.15it/s, loss=0.000077]"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-4239d6e7db81>\u001b[0m in \u001b[0;36m<cell line: 32>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;31m## train loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;31m# final test\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdataloader_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-8-c358b8fb4b7a>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, optimizer, dataloader_train, dataloader_val)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mtq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_description\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch %d, lr %f'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss_record\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloader_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m             \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    629\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 630\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    631\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1328\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1329\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1292\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1294\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1295\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1132\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1133\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}